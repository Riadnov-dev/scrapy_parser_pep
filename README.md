# ğŸ•·ï¸ Scrapy PEP Parser

**Scrapy PEP Parser** is a Python-based web scraper built with [Scrapy](https://scrapy.org/) to extract information from the [Python Enhancement Proposals (PEP)](https://peps.python.org/) website.  
It collects data on all PEPs â€” including their number, title, and status â€” and saves it into **two CSV files**:  
- ğŸ“„ **PEP List**: number, title, status for each proposal  
- ğŸ“Š **Status Summary**: aggregated statistics by status type


## ğŸ§° Tech Stack

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)
[![Scrapy](https://img.shields.io/badge/Scrapy-Web%20Crawler-0A8C5F?logo=scrapy)](https://scrapy.org/)
[![ItemLoaders](https://img.shields.io/badge/ItemLoaders-Data%20Parsing%20Helpers-FF9800?logo=python)](https://docs.scrapy.org/en/latest/topics/loaders.html)
[![Logging](https://img.shields.io/badge/Logging-built--in-lightgrey?logo=python)](https://docs.python.org/3/library/logging.html)
[![CSV Export](https://img.shields.io/badge/CSV%20Export-built--in-blue?logo=python)](https://docs.python.org/3/library/csv.html)



## âœ¨ Features
- Full PEP parsing from the official Python website
- Data stored in clean CSV format
- Status aggregation with document counts
- `ItemLoaders` for structured and normalized data
- Configurable settings in `settings.py`
- Detailed logging for debugging



### ğŸ“¦ Installation

1. **Clone the repository**  
```
git clone https://github.com/Riadnov-dev/scrapy_parser_pep.git

cd scrapy_parser_pep
```

2. **Create and activate a virtual environment**
```
python -m venv venv

source venv/bin/activate  # On Windows: venv\Scripts\activate
```
3. **Install dependencies**

```
pip install -r requirements.txt
```

### ğŸš€ Usage
Run the pep spider:

```
scrapy crawl pep
```

After execution, two CSV files will be created inside the results/ directory:

pep_<datetime>.csv â€” full list of PEPs with number, title, and status

status_summary_<datetime>.csv â€” aggregated count of PEPs by status

### ğŸ“‚ Project Structure

```
scrapy_parser_pep/
 â”œâ”€â”€ pep_parse/
 â”‚   â”œâ”€â”€ spiders/
 â”‚   â”‚   â”œâ”€â”€ __init__.py
 â”‚   â”‚   â””â”€â”€ pep.py
 â”‚   â”œâ”€â”€ __init__.py
 â”‚   â”œâ”€â”€ items.py
 â”‚   â”œâ”€â”€ middlewares.py
 â”‚   â”œâ”€â”€ pipelines.py
 â”‚   â””â”€â”€ settings.py
 â”œâ”€â”€ results/
 â”‚   â”œâ”€â”€ pep_<datetime>.csv
 â”‚   â””â”€â”€ status_summary_<datetime>.csv
 â”œâ”€â”€ tests/
 â”œâ”€â”€ .flake8
 â”œâ”€â”€ .gitignore
 â”œâ”€â”€ README.md
 â”œâ”€â”€ pytest.ini
 â”œâ”€â”€ requirements.txt
 â””â”€â”€ scrapy.cfg
```

### ğŸ‘¤ Author
Nikita Riadnov

GitHub: https://github.com/Riadnov-dev
