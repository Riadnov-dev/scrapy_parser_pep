# ğŸ•·ï¸ Scrapy PEP Parser

A **Python web scraper** built with **Scrapy** to extract data from the [Python Enhancement Proposals (PEP)](https://peps.python.org/) website.  
It collects structured information on all PEPs and saves it into **two CSV files**:  

- ğŸ“„ **PEP List** â€” number, title, and status for each proposal  
- ğŸ“Š **Status Summary** â€” aggregated statistics by status type  

---

## ğŸ§° Tech Stack

<img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/> <img src="https://img.shields.io/badge/Scrapy-0A8C5F?style=for-the-badge&logo=scrapy&logoColor=white"/> <img src="https://img.shields.io/badge/ItemLoaders-FF9800?style=for-the-badge&logo=python&logoColor=white"/> <img src="https://img.shields.io/badge/CSV%20Export-000000?style=for-the-badge&logo=csv&logoColor=white"/> <img src="https://img.shields.io/badge/Logging-808080?style=for-the-badge&logo=python&logoColor=white"/>

---

## âœ¨ Features

- ğŸ•¸ï¸ **Full PEP parsing** from the official Python website  
- ğŸ“‚ **CSV export** â€” structured results for further analysis  
- ğŸ“Š **Status aggregation** with counts by type  
- âš™ï¸ **ItemLoaders** for structured and normalized data  
- ğŸ› ï¸ **Configurable settings** in `settings.py`  
- ğŸ“‘ **Detailed logging** for debugging and transparency  

---




### ğŸ“¦ Installation

1. **Clone the repository**  
```
git clone https://github.com/Riadnov-dev/scrapy_parser_pep.git

cd scrapy_parser_pep
```

2. **Create and activate a virtual environment**
```
python -m venv venv

source venv/bin/activate  # On Windows: venv\Scripts\activate
```
3. **Install dependencies**

```
pip install -r requirements.txt
```

### ğŸš€ Usage
Run the pep spider:

```
scrapy crawl pep
```

After execution, two CSV files will be created inside the results/ directory:

pep_<datetime>.csv â€” full list of PEPs with number, title, and status

status_summary_<datetime>.csv â€” aggregated count of PEPs by status

### ğŸ“‚ Project Structure

```
scrapy_parser_pep/
 â”œâ”€â”€ pep_parse/
 â”‚   â”œâ”€â”€ spiders/
 â”‚   â”‚   â”œâ”€â”€ __init__.py
 â”‚   â”‚   â””â”€â”€ pep.py
 â”‚   â”œâ”€â”€ __init__.py
 â”‚   â”œâ”€â”€ items.py
 â”‚   â”œâ”€â”€ middlewares.py
 â”‚   â”œâ”€â”€ pipelines.py
 â”‚   â””â”€â”€ settings.py
 â”œâ”€â”€ results/
 â”‚   â”œâ”€â”€ pep_<datetime>.csv
 â”‚   â””â”€â”€ status_summary_<datetime>.csv
 â”œâ”€â”€ tests/
 â”œâ”€â”€ .flake8
 â”œâ”€â”€ .gitignore
 â”œâ”€â”€ README.md
 â”œâ”€â”€ pytest.ini
 â”œâ”€â”€ requirements.txt
 â””â”€â”€ scrapy.cfg
```

### ğŸ‘¤ Author
Nikita Riadnov

GitHub: https://github.com/Riadnov-dev
